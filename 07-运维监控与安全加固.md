# 运维监控与安全加固

## 第一章 运维监控方案

### 1.1 日志管理

#### 1.1.1 结构化日志格式

```python
# app/core/logging.py
from loguru import logger

logger.add("app.log", rotation="500 MB", format="{time} {level} {message}", serialize=True)

# 使用示例
logger.info("Production overview requested", extra={
    "user_id": "user-123",
    "line_id": "LINE-A",
    "time_range": "24h",
    "response_time": 245
})

logger.error("Database connection failed", extra={
    "error": str(err),
    "stack": err.__traceback__
})
```

#### 1.1.2 日志级别定义

| 级别 | 用途 | 示例 |
|------|------|------|
| ERROR | 系统错误、异常 | 数据库连接失败、API调用超时 |
| WARN | 警告信息 | 缓存未命中、配置缺失使用默认值 |
| INFO | 关键业务操作 | 用户登录、创建工单、方案执行 |
| DEBUG | 调试信息 | SQL查询、数据转换过程 |
| TRACE | 详细追踪 | 函数调用链路、变量值 |

### 1.2 应用性能监控（APM）

#### 1.2.1 集成Prometheus监控

```python
# app/middleware/prometheus.py
from prometheus_client import Histogram, Counter, Gauge
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware

REQUEST_DURATION = Histogram('http_request_duration_ms', 'HTTP request duration', ['method', 'path', 'status'])
REQUEST_TOTAL = Counter('http_requests_total', 'Total HTTP requests', ['method', 'path', 'status'])
WS_CONNECTIONS = Gauge('websocket_active_connections', 'Active WebSocket connections')

class PrometheusMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        response = await call_next(request)
        duration = (time.time() - start_time) * 1000

        REQUEST_DURATION.labels(request.method, request.url.path, response.status_code).observe(duration)
        REQUEST_TOTAL.labels(request.method, request.url.path, response.status_code).inc()

        return response

# 在main.py中添加
app.add_middleware(PrometheusMiddleware)

# 暴露metrics端点
from prometheus_client import make_asgi_app
app.mount("/metrics", make_asgi_app())
```

#### 1.2.2 Grafana仪表盘配置

```json
{
  "dashboard": {
    "title": "观澜司南系统监控",
    "panels": [
      {
        "title": "API请求响应时间（P95）",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_ms_bucket[5m]))"
          }
        ]
      },
      {
        "title": "API请求QPS",
        "targets": [
          {
            "expr": "rate(http_requests_total[1m])"
          }
        ]
      },
      {
        "title": "WebSocket活跃连接数",
        "targets": [
          {
            "expr": "websocket_active_connections"
          }
        ]
      },
      {
        "title": "错误率",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])"
          }
        ]
      }
    ]
  }
}
```

### 1.3 告警规则配置

```yaml
# alertmanager-rules.yml
groups:
  - name: application_alerts
    interval: 30s
    rules:
      # API响应时间告警
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(http_request_duration_ms_bucket[5m])) > 2000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API响应时间过高"
          description: "P95响应时间超过2秒，当前值: {{ $value }}ms"

      # 错误率告警
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "API错误率过高"
          description: "错误率超过5%，当前值: {{ $value }}"

      # 数据库连接池告警
      - alert: DatabaseConnectionPoolExhausted
        expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "数据库连接池即将耗尽"
          description: "连接使用率超过80%"

      # Celery任务延迟告警
      - alert: CeleryTaskLag
        expr: celery_task_latency_seconds > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Celery任务延迟过高"
          description: "任务延迟超过10秒"
```

### 1.4 备份与容灾

#### 1.4.1 数据备份策略

```bash
#!/bin/bash
# backup-databases.sh

# PostgreSQL备份
pg_dump -h $PG_HOST -U $PG_USER -d app | gzip > /backup/postgres/app_$(date +%Y%m%d).sql.gz

# InfluxDB备份
influx backup -portable -host $INFLUX_HOST /backup/influxdb/$(date +%Y%m%d)

# Neo4j备份
neo4j-admin dump --database=neo4j --to=/backup/neo4j/neo4j_$(date +%Y%m%d).dump

# MinIO备份（同步至异地存储）
mc mirror minio/images s3-remote/images-backup

# 清理30天前的备份
find /backup -type f -mtime +30 -delete
```

#### 1.4.2 容灾恢复计划

| 场景 | RTO（恢复时间目标） | RPO（数据恢复点） | 恢复步骤 |
|------|-------------------|-----------------|---------|
| 单个服务故障 | < 5分钟 | 0 | K8s自动重启Pod |
| 数据库主节点故障 | < 10分钟 | < 1分钟 | 自动故障转移至从节点 |
| 整个集群故障 | < 1小时 | < 1小时 | 从备份恢复至备用集群 |
| 整个数据中心级灾难 | < 4小时 | < 24小时 | 从异地备份恢复 |

---

## 第二章 安全加固措施

### 2.1 应用层安全

#### 2.1.1 SQL注入防护

```python
# 使用参数化查询
async def get_line(db: AsyncSession, line_id: str):
    query = select(ProductionLine).where(ProductionLine.line_id == line_id)  # 参数化
    return await db.scalar(query)

# 禁止直接拼接SQL
# ❌ 错误示例
query = f"SELECT * FROM production_lines WHERE line_id = '{line_id}'"

# ✅ 正确示例
query = text("SELECT * FROM production_lines WHERE line_id = :line_id")
result = await db.execute(query, {"line_id": line_id})
```

#### 2.1.2 XSS防护

```python
# 后端：对输出进行HTML转义
from html import escape

safe_description = escape(user_input.description)
```

#### 2.1.3 CSRF防护

模板内置CSRF支持，通过`fastapi-csrf-protect`扩展。

```python
from fastapi_csrf_protect import CsrfProtect

# 在API中使用
@router.post("/form")
async def form(csrf_protect: CsrfProtect = Depends()):
    csrf_protect.validate_csrf_in_cookies(request)
    # ...
```

### 2.2 数据加密

```python
# 敏感字段加密
import secrets
from cryptography.fernet import Fernet

key = Fernet.generate_key()  # 或从环境变量加载
cipher = Fernet(key)

def encrypt(text: str) -> str:
    return cipher.encrypt(text.encode()).decode()

def decrypt(encrypted: str) -> str:
    return cipher.decrypt(encrypted.encode()).decode()
```

### 2.3 安全检查清单

- [ ] 所有API接口都有认证授权
- [ ] 敏感操作记录审计日志
- [ ] 密码使用argon2加密存储（模板支持）
- [ ] HTTPS强制使用（HSTS头）
- [ ] 设置安全响应头（CSP、X-Frame-Options等）
- [ ] 文件上传大小限制与类型验证
- [ ] 定期依赖包漏洞扫描（pip check）
- [ ] 数据库连接使用最小权限账号
- [ ] 生产环境禁用调试模式
- [ ] 定期进行渗透测试