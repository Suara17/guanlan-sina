# 数据存储设计

## 1. PostgreSQL - 业务数据库

### 1.1 表结构设计

```sql
-- 产线信息表
CREATE TABLE production_lines (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    line_name VARCHAR(100) NOT NULL,
    factory_id UUID NOT NULL,
    status VARCHAR(20) DEFAULT 'active',
    current_status VARCHAR(20) DEFAULT 'idle',  -- running/timeout/idle/maintenance
    current_plan_id UUID REFERENCES production_plans(id),
    bottleneck_station_id UUID REFERENCES stations(id),
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 工位信息表
CREATE TABLE stations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    station_name VARCHAR(100) NOT NULL,
    line_id UUID REFERENCES production_lines(id),
    station_type VARCHAR(50),
    sequence_order INT,
    equipment_ids TEXT[],
    current_cycle_time DECIMAL(10, 2),  -- 当前CT值
    wip_quantity INT DEFAULT 0,  -- 当前WIP数量
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 生产计划表（观澜系统核心表）
CREATE TABLE production_plans (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    line_id UUID REFERENCES production_lines(id),
    product_id UUID,
    product_name VARCHAR(200),
    planned_quantity INT NOT NULL,  -- 计划生产量
    actual_quantity INT DEFAULT 0,  -- 实时生产量
    start_time TIMESTAMP NOT NULL,
    estimated_completion_time TIMESTAMP,  -- 预计完成时间
    actual_completion_time TIMESTAMP,
    status VARCHAR(20) DEFAULT 'planned',  -- planned/running/completed/timeout
    created_by UUID,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_line_status (line_id, status),
    INDEX idx_start_time (start_time)
);

-- 生产记录表（实时生产数据）
CREATE TABLE production_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    plan_id UUID REFERENCES production_plans(id),
    line_id UUID REFERENCES production_lines(id),
    station_id UUID REFERENCES stations(id),
    product_id UUID,
    batch_id VARCHAR(50),
    quantity INT DEFAULT 1,
    quality_status VARCHAR(20),  -- good/defect/rework
    defect_type VARCHAR(100),
    cycle_time DECIMAL(10, 2),  -- 实际CT
    recorded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_plan_recorded (plan_id, recorded_at),
    INDEX idx_line_station (line_id, station_id, recorded_at)
);

-- 质量指标表（良品率统计）
CREATE TABLE quality_metrics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    plan_id UUID REFERENCES production_plans(id),
    line_id UUID REFERENCES production_lines(id),
    station_id UUID REFERENCES stations(id),  -- NULL表示产线整体
    total_produced INT DEFAULT 0,
    good_quantity INT DEFAULT 0,
    defect_quantity INT DEFAULT 0,
    rework_quantity INT DEFAULT 0,
    yield_rate DECIMAL(5, 2),  -- 良品率
    defect_rate DECIMAL(5, 2),  -- 不良品率
    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_plan_calculated (plan_id, calculated_at),
    INDEX idx_line_station (line_id, station_id, calculated_at)
);

-- 缺陷明细表（支持缺陷图像墙）
CREATE TABLE defect_details (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    record_id UUID REFERENCES production_records(id),
    plan_id UUID REFERENCES production_plans(id),
    line_id UUID REFERENCES production_lines(id),
    station_id UUID REFERENCES stations(id),
    defect_type VARCHAR(100),  -- 划痕/污点/尺寸超差等
    severity VARCHAR(20),  -- high/medium/low
    defect_image_url TEXT,  -- MinIO对象路径
    confidence DECIMAL(5, 2),  -- 检测置信度
    detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_plan_type (plan_id, defect_type),
    INDEX idx_station_severity (station_id, severity, detected_at)
);

-- 异常记录表
CREATE TABLE anomalies (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    line_id UUID REFERENCES production_lines(id),
    station_id UUID REFERENCES stations(id),
    defect_type VARCHAR(100),
    severity VARCHAR(20),
    detected_at TIMESTAMP NOT NULL,
    status VARCHAR(20) DEFAULT 'open',
    assigned_to UUID,
    root_cause TEXT,
    solution_id UUID,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    closed_at TIMESTAMP
);

-- 处置方案表
CREATE TABLE solutions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    anomaly_id UUID REFERENCES anomalies(id),
    solution_type VARCHAR(50),
    solution_name VARCHAR(200),
    description TEXT,
    estimated_downtime_hours DECIMAL(10, 2),
    success_rate DECIMAL(5, 2),
    expected_loss DECIMAL(15, 2),
    roi DECIMAL(10, 2),
    simulation_result JSONB,
    recommended BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 执行工单表
CREATE TABLE work_orders (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    solution_id UUID REFERENCES solutions(id),
    order_type VARCHAR(50),
    responsible_person VARCHAR(100),
    instructions TEXT,
    estimated_duration_hours DECIMAL(5, 2),
    actual_duration_hours DECIMAL(5, 2),
    status VARCHAR(20) DEFAULT 'pending',
    execution_result VARCHAR(20),
    actual_loss DECIMAL(15, 2),
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- 案例库表
CREATE TABLE case_library (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    anomaly_id UUID REFERENCES anomalies(id),
    problem_description TEXT,
    diagnosis_result JSONB,
    solution_adopted UUID,
    expected_effect JSONB,
    actual_effect JSONB,
    lessons_learned TEXT,
    tags TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_tags USING GIN (tags)
);

-- 用户表
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(100),
    phone VARCHAR(20),
    role VARCHAR(50),
    factory_ids TEXT[],
    line_ids TEXT[],
    permissions TEXT[],  -- 扩展RBAC权限列表
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login_at TIMESTAMP
);

-- 操作日志表
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID,
    action VARCHAR(100),
    resource_type VARCHAR(50),
    resource_id VARCHAR(50),
    ip_address VARCHAR(50),
    user_agent TEXT,
    request_body JSONB,
    response_status INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 1.2 SQLAlchemy模型示例

```python
# app/models/production.py
import uuid
from datetime import datetime
from typing import Optional, List
from sqlmodel import Field, Relationship, SQLModel
from sqlalchemy import Column, Index, text
from sqlalchemy.dialects.postgresql import JSONB, ARRAY

# Shared properties
class ProductionLineBase(SQLModel):
    line_name: str = Field(max_length=100)
    factory_id: uuid.UUID = Field(foreign_key="factories.id")
    status: str = Field(default="active", max_length=20)
    current_status: str = Field(default="idle", max_length=20)

# Database model
class ProductionLine(ProductionLineBase, table=True):
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    current_plan_id: Optional[uuid.UUID] = Field(default=None, foreign_key="production_plans.id")
    bottleneck_station_id: Optional[uuid.UUID] = Field(default=None, foreign_key="stations.id")
    last_updated: datetime = Field(default_factory=datetime.utcnow)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)
    stations: list["Station"] = Relationship(back_populates="line")
    plans: list["ProductionPlan"] = Relationship(back_populates="line")

# Shared properties
class ProductionPlanBase(SQLModel):
    line_id: uuid.UUID
    product_name: Optional[str] = Field(default=None, max_length=200)
    planned_quantity: int
    actual_quantity: int = Field(default=0)
    start_time: datetime
    estimated_completion_time: Optional[datetime] = None
    actual_completion_time: Optional[datetime] = None
    status: str = Field(default="planned", max_length=20)

# Database model
class ProductionPlan(ProductionPlanBase, table=True):
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    product_id: Optional[uuid.UUID] = Field(default=None)
    created_by: Optional[uuid.UUID] = Field(default=None)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

# Shared properties
class ProductionRecordBase(SQLModel):
    plan_id: uuid.UUID
    line_id: uuid.UUID
    station_id: uuid.UUID
    product_id: Optional[uuid.UUID] = Field(default=None)
    batch_id: Optional[str] = Field(default=None, max_length=50)
    quantity: int = Field(default=1)
    quality_status: Optional[str] = Field(default=None, max_length=20)
    defect_type: Optional[str] = Field(default=None, max_length=100)
    cycle_time: Optional[float] = Field(default=None)

# Database model
class ProductionRecord(ProductionRecordBase, table=True):
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    recorded_at: datetime = Field(default_factory=datetime.utcnow)

# Shared properties
class QualityMetricBase(SQLModel):
    plan_id: uuid.UUID
    line_id: uuid.UUID
    station_id: Optional[uuid.UUID] = Field(default=None)
    total_produced: int = Field(default=0)
    good_quantity: int = Field(default=0)
    defect_quantity: int = Field(default=0)
    rework_quantity: int = Field(default=0)
    yield_rate: Optional[float] = Field(default=None)
    defect_rate: Optional[float] = Field(default=None)

# Database model
class QualityMetric(QualityMetricBase, table=True):
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    calculated_at: datetime = Field(default_factory=datetime.utcnow)

# Shared properties
class DefectDetailBase(SQLModel):
    record_id: uuid.UUID
    plan_id: uuid.UUID
    line_id: uuid.UUID
    station_id: uuid.UUID
    defect_type: str = Field(max_length=100)
    severity: str = Field(max_length=20)
    defect_image_url: Optional[str] = Field(default=None)
    confidence: Optional[float] = Field(default=None)

# Database model
class DefectDetail(DefectDetailBase, table=True):
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    detected_at: datetime = Field(default_factory=datetime.utcnow)
```

---

## 2. 其他数据库扩展

### 2.1 InfluxDB - 时序数据

用于时序数据，如生产指标趋势。FastAPI 通过 influxdb-client-python 扩展集成。

**Measurement配置**:

| Measurement名称 | Tags | Fields | 用途 |
|----------------|------|--------|------|
| `production_metrics` | line_id, station_id, plan_id | yield_rate, cycle_time, throughput, wip_quantity | 生产指标实时监控 |
| `line_status` | line_id, status_type | status_value, duration | 产线状态变化记录 |
| `bottleneck_detection` | line_id, bottleneck_station | severity, congestion_level, wip_depth | 瓶颈检测与热力图数据 |
| `quality_trends` | line_id, defect_type | defect_count, defect_rate, confidence | 缺陷趋势分析 |

```python
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
from datetime import datetime

# 写入生产指标
client = InfluxDBClient(url="http://localhost:8086", token="token", org="company")
write_api = client.write_api(write_options=SYNCHRONOUS)

# 生产指标记录
point = Point("production_metrics") \
    .tag("line_id", "LINE-A") \
    .tag("station_id", "W05") \
    .tag("plan_id", "PLAN-001") \
    .field("yield_rate", 95.2) \
    .field("cycle_time", 45.5) \
    .field("throughput", 120) \
    .field("wip_quantity", 15) \
    .time(datetime.utcnow())

# 产线状态记录
status_point = Point("line_status") \
    .tag("line_id", "LINE-A") \
    .tag("status_type", "running") \
    .field("status_value", 1.0) \
    .field("duration", 3600.0) \
    .time(datetime.utcnow())

# 瓶颈检测记录
bottleneck_point = Point("bottleneck_detection") \
    .tag("line_id", "LINE-A") \
    .tag("bottleneck_station", "W05") \
    .field("severity", 0.85) \
    .field("congestion_level", 0.72) \
    .field("wip_depth", 25) \
    .time(datetime.utcnow())

write_api.write(bucket="production", record=point)
write_api.write(bucket="production", record=status_point)
write_api.write(bucket="production", record=bottleneck_point)
```

### 2.2 Neo4j - 知识图谱

用于知识图谱。FastAPI 通过 neomodel 或 neo4j-driver 扩展集成。

```python
from neomodel import StructuredNode, StringProperty, RelationshipTo, config

# 配置连接
config.DATABASE_URL = 'bolt://neo4j:password@localhost:7687'

class ProblemNode(StructuredNode):
    node_id = StringProperty(unique_index=True, required=True)
    label = StringProperty(required=True)
    node_type = StringProperty(required=True)

    # 关系
    causes = RelationshipTo('CauseNode', 'CAUSED_BY')
    evidences = RelationshipTo('EvidenceNode', 'HAS_EVIDENCE')

class CauseNode(StructuredNode):
    node_id = StringProperty(unique_index=True, required=True)
    label = StringProperty(required=True)
    confidence = FloatProperty()

    caused_by = RelationshipTo('ProblemNode', 'CAUSES')

class EvidenceNode(StructuredNode):
    node_id = StringProperty(unique_index=True, required=True)
    label = StringProperty(required=True)
    evidence_type = StringProperty(required=True)

    supports = RelationshipTo('ProblemNode', 'SUPPORTS')
```

### 2.3 MinIO - 对象存储

用于对象存储（如缺陷图像）。FastAPI 通过 boto3 或 minio-python 扩展集成。

```python
from minio import Minio
from minio.error import S3Error

client = Minio(
    "localhost:9000",
    access_key="admin",
    secret_key="securepassword",
    secure=False
)

# 上传图像
def upload_defect_image(image_path: str, object_name: str):
    client.fput_object(
        "defect-images",
        object_name,
        image_path
    )

# 下载图像
def download_defect_image(object_name: str, save_path: str):
    client.fget_object(
        "defect-images",
        object_name,
        save_path
    )
```

### 2.4 Redis - 缓存与队列

用于缓存和Celery消息队列。模板已内置支持。

```python
import redis

# 缓存示例
r = redis.Redis(host='localhost', port=6379, db=0)

def cache_production_overview(line_id: str, data: dict, ttl: int = 300):
    key = f"production:overview:{line_id}"
    r.setex(key, ttl, json.dumps(data))

def get_cached_production_overview(line_id: str):
    key = f"production:overview:{line_id}"
    data = r.get(key)
    return json.loads(data) if data else None
```

---

## 3. 部署架构设计

### 3.1 Docker Compose配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Traefik反向代理（模板内置）
  traefik:
    image: traefik:v2.10
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./traefik.yml:/etc/traefik/traefik.yml
    networks:
      - app-network

  # FastAPI服务
  backend:
    build: ./backend
    environment:
      - APP_MODULE=app.main:app
      - BACKEND_CORS_ORIGINS=["*"]
      - DATABASE_URL=postgresql://admin:securepassword@postgres:5432/app
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    labels:
      - "traefik.http.routers.api.rule=PathPrefix(`/api`)"
    networks:
      - app-network

  # Celery Worker
  celery_worker:
    build: ./backend
    command: celery -A app.core.celery worker --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - DATABASE_URL=postgresql://admin:securepassword@postgres:5432/app
    depends_on:
      - redis
      - postgres
    networks:
      - app-network

  # PostgreSQL数据库
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=securepassword
      - POSTGRES_DB=app
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - app-network

  # Redis缓存/队列
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - app-network

  # InfluxDB时序数据库（扩展）
  influxdb:
    image: influxdb:2.7-alpine
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=securepassword
      - DOCKER_INFLUXDB_INIT_ORG=company
      - DOCKER_INFLUXDB_INIT_BUCKET=production
    volumes:
      - influxdb-data:/var/lib/influxdb2
    networks:
      - app-network

  # Neo4j图数据库（扩展）
  neo4j:
    image: neo4j:5.13-community
    environment:
      - NEO4J_AUTH=neo4j/securepassword
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j-data:/data
    networks:
      - app-network

  # MinIO对象存储（扩展）
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=securepassword
    volumes:
      - minio-data:/data
    networks:
      - app-network

volumes:
  postgres-data:
  redis-data:
  influxdb-data:
  neo4j-data:
  minio-data:

networks:
  app-network:
    driver: bridge
```

### 3.2 Kubernetes部署配置

```yaml
# k8s/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: registry.company.com/backend:latest
        ports:
        - containerPort: 8000
        env:
          - name: DATABASE_URL
            valueFrom:
              secretKeyRef:
                name: db-secrets
                key: postgres-url
          - name: REDIS_URL
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: redis-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: production
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```
