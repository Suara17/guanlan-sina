# 数据存储设计

## 1. PostgreSQL - 业务数据库

### 1.1 表结构设计

```sql
-- 产线信息表
CREATE TABLE production_lines (
    line_id VARCHAR(50) PRIMARY KEY,
    line_name VARCHAR(100) NOT NULL,
    factory_id VARCHAR(50) NOT NULL,
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 工位信息表
CREATE TABLE stations (
    station_id VARCHAR(50) PRIMARY KEY,
    station_name VARCHAR(100) NOT NULL,
    line_id VARCHAR(50) REFERENCES production_lines(line_id),
    station_type VARCHAR(50),
    sequence_order INT,
    equipment_ids TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 异常记录表
CREATE TABLE anomalies (
    anomaly_id VARCHAR(50) PRIMARY KEY,
    line_id VARCHAR(50) REFERENCES production_lines(line_id),
    station_id VARCHAR(50) REFERENCES stations(station_id),
    defect_type VARCHAR(100),
    severity VARCHAR(20),
    detected_at TIMESTAMP NOT NULL,
    status VARCHAR(20) DEFAULT 'open',
    assigned_to VARCHAR(50),
    root_cause TEXT,
    solution_id VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    closed_at TIMESTAMP
);

-- 处置方案表
CREATE TABLE solutions (
    solution_id VARCHAR(50) PRIMARY KEY,
    anomaly_id VARCHAR(50) REFERENCES anomalies(anomaly_id),
    solution_type VARCHAR(50),
    solution_name VARCHAR(200),
    description TEXT,
    estimated_downtime_hours DECIMAL(10, 2),
    success_rate DECIMAL(5, 2),
    expected_loss DECIMAL(15, 2),
    roi DECIMAL(10, 2),
    simulation_result JSONB,
    recommended BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 执行工单表
CREATE TABLE work_orders (
    order_id VARCHAR(50) PRIMARY KEY,
    solution_id VARCHAR(50) REFERENCES solutions(solution_id),
    order_type VARCHAR(50),
    responsible_person VARCHAR(100),
    instructions TEXT,
    estimated_duration_hours DECIMAL(5, 2),
    actual_duration_hours DECIMAL(5, 2),
    status VARCHAR(20) DEFAULT 'pending',
    execution_result VARCHAR(20),
    actual_loss DECIMAL(15, 2),
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- 案例库表
CREATE TABLE case_library (
    case_id VARCHAR(50) PRIMARY KEY,
    anomaly_id VARCHAR(50) REFERENCES anomalies(anomaly_id),
    problem_description TEXT,
    diagnosis_result JSONB,
    solution_adopted VARCHAR(50),
    expected_effect JSONB,
    actual_effect JSONB,
    lessons_learned TEXT,
    tags TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_tags USING GIN (tags)
);

-- 用户表
CREATE TABLE users (
    user_id VARCHAR(50) PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(100),
    phone VARCHAR(20),
    role VARCHAR(50),
    factory_ids TEXT[],
    line_ids TEXT[],
    permissions TEXT[],  -- 扩展RBAC权限列表
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login_at TIMESTAMP
);

-- 操作日志表
CREATE TABLE audit_logs (
    log_id BIGSERIAL PRIMARY KEY,
    user_id VARCHAR(50),
    action VARCHAR(100),
    resource_type VARCHAR(50),
    resource_id VARCHAR(50),
    ip_address VARCHAR(50),
    user_agent TEXT,
    request_body JSONB,
    response_status INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 1.2 SQLAlchemy模型示例

```python
# app/db/models/production.py
from sqlalchemy import Column, String, Integer, ForeignKey, TIMESTAMP, ARRAY, text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.dialects.postgresql import JSONB

Base = declarative_base()

class ProductionLine(Base):
    __tablename__ = "production_lines"

    line_id = Column(String(50), primary_key=True)
    line_name = Column(String(100), nullable=False)
    factory_id = Column(String(50), nullable=False)
    status = Column(String(20), server_default="active")
    created_at = Column(TIMESTAMP, server_default=text("CURRENT_TIMESTAMP"))
    updated_at = Column(TIMESTAMP, server_default=text("CURRENT_TIMESTAMP"))
```

---

## 2. 其他数据库扩展

### 2.1 InfluxDB - 时序数据

用于时序数据，如生产指标趋势。FastAPI 通过 influxdb-client-python 扩展集成。

**Measurement配置**:
```python
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS

# 写入时序数据
client = InfluxDBClient(url="http://localhost:8086", token="token", org="company")
write_api = client.write_api(write_options=SYNCHRONOUS)

point = Point("production_metrics") \
    .tag("line_id", "LINE-A") \
    .tag("station_id", "W05") \
    .field("yield_rate", 95.2) \
    .field("cycle_time", 45.5) \
    .time(datetime.utcnow())

write_api.write(bucket="production", record=point)
```

### 2.2 Neo4j - 知识图谱

用于知识图谱。FastAPI 通过 neomodel 或 neo4j-driver 扩展集成。

```python
from neomodel import StructuredNode, StringProperty, RelationshipTo, config

# 配置连接
config.DATABASE_URL = 'bolt://neo4j:password@localhost:7687'

class ProblemNode(StructuredNode):
    node_id = StringProperty(unique_index=True, required=True)
    label = StringProperty(required=True)
    node_type = StringProperty(required=True)

    # 关系
    causes = RelationshipTo('CauseNode', 'CAUSED_BY')
    evidences = RelationshipTo('EvidenceNode', 'HAS_EVIDENCE')

class CauseNode(StructuredNode):
    node_id = StringProperty(unique_index=True, required=True)
    label = StringProperty(required=True)
    confidence = FloatProperty()

    caused_by = RelationshipTo('ProblemNode', 'CAUSES')

class EvidenceNode(StructuredNode):
    node_id = StringProperty(unique_index=True, required=True)
    label = StringProperty(required=True)
    evidence_type = StringProperty(required=True)

    supports = RelationshipTo('ProblemNode', 'SUPPORTS')
```

### 2.3 MinIO - 对象存储

用于对象存储（如缺陷图像）。FastAPI 通过 boto3 或 minio-python 扩展集成。

```python
from minio import Minio
from minio.error import S3Error

client = Minio(
    "localhost:9000",
    access_key="admin",
    secret_key="securepassword",
    secure=False
)

# 上传图像
def upload_defect_image(image_path: str, object_name: str):
    client.fput_object(
        "defect-images",
        object_name,
        image_path
    )

# 下载图像
def download_defect_image(object_name: str, save_path: str):
    client.fget_object(
        "defect-images",
        object_name,
        save_path
    )
```

### 2.4 Redis - 缓存与队列

用于缓存和Celery消息队列。模板已内置支持。

```python
import redis

# 缓存示例
r = redis.Redis(host='localhost', port=6379, db=0)

def cache_production_overview(line_id: str, data: dict, ttl: int = 300):
    key = f"production:overview:{line_id}"
    r.setex(key, ttl, json.dumps(data))

def get_cached_production_overview(line_id: str):
    key = f"production:overview:{line_id}"
    data = r.get(key)
    return json.loads(data) if data else None
```

---

## 3. 部署架构设计

### 3.1 Docker Compose配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Traefik反向代理（模板内置）
  traefik:
    image: traefik:v2.10
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./traefik.yml:/etc/traefik/traefik.yml
    networks:
      - app-network

  # FastAPI服务
  backend:
    build: ./backend
    environment:
      - APP_MODULE=app.main:app
      - BACKEND_CORS_ORIGINS=["*"]
      - DATABASE_URL=postgresql://admin:securepassword@postgres:5432/app
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    labels:
      - "traefik.http.routers.api.rule=PathPrefix(`/api`)"
    networks:
      - app-network

  # Celery Worker
  celery_worker:
    build: ./backend
    command: celery -A app.core.celery worker --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - DATABASE_URL=postgresql://admin:securepassword@postgres:5432/app
    depends_on:
      - redis
      - postgres
    networks:
      - app-network

  # PostgreSQL数据库
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=securepassword
      - POSTGRES_DB=app
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - app-network

  # Redis缓存/队列
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - app-network

  # InfluxDB时序数据库（扩展）
  influxdb:
    image: influxdb:2.7-alpine
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=securepassword
      - DOCKER_INFLUXDB_INIT_ORG=company
      - DOCKER_INFLUXDB_INIT_BUCKET=production
    volumes:
      - influxdb-data:/var/lib/influxdb2
    networks:
      - app-network

  # Neo4j图数据库（扩展）
  neo4j:
    image: neo4j:5.13-community
    environment:
      - NEO4J_AUTH=neo4j/securepassword
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j-data:/data
    networks:
      - app-network

  # MinIO对象存储（扩展）
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=securepassword
    volumes:
      - minio-data:/data
    networks:
      - app-network

volumes:
  postgres-data:
  redis-data:
  influxdb-data:
  neo4j-data:
  minio-data:

networks:
  app-network:
    driver: bridge
```

### 3.2 Kubernetes部署配置

```yaml
# k8s/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: registry.company.com/backend:latest
        ports:
        - containerPort: 8000
        env:
          - name: DATABASE_URL
            valueFrom:
              secretKeyRef:
                name: db-secrets
                key: postgres-url
          - name: REDIS_URL
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: redis-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: production
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```